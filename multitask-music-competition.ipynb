{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-18T00:06:58.482403Z",
     "iopub.status.busy": "2021-01-18T00:06:58.481689Z",
     "iopub.status.idle": "2021-01-18T00:07:00.357301Z",
     "shell.execute_reply": "2021-01-18T00:07:00.356074Z"
    },
    "papermill": {
     "duration": 1.891101,
     "end_time": "2021-01-18T00:07:00.357414",
     "exception": false,
     "start_time": "2021-01-18T00:06:58.466313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import SubsetRandomSampler, DataLoader\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy.stats import spearmanr as corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007602,
     "end_time": "2021-01-18T00:07:00.373758",
     "exception": false,
     "start_time": "2021-01-18T00:07:00.366156",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Step 9b: Multitask Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-18T00:07:00.417416Z",
     "iopub.status.busy": "2021-01-18T00:07:00.415637Z",
     "iopub.status.idle": "2021-01-18T00:07:00.418029Z",
     "shell.execute_reply": "2021-01-18T00:07:00.418449Z"
    },
    "papermill": {
     "duration": 0.037032,
     "end_time": "2021-01-18T00:07:00.418547",
     "exception": false,
     "start_time": "2021-01-18T00:07:00.381515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper functions to read fused, mel, and chromagram\n",
    "def read_fused_spectrogram(spectrogram_file):\n",
    "    spectrogram = np.load(spectrogram_file)\n",
    "    return spectrogram.T\n",
    "\n",
    "def torch_train_val_split(\n",
    "        dataset, batch_train, batch_eval,\n",
    "        val_size=.2, shuffle=True, seed=None):\n",
    "    # Creating data indices for training and validation splits:\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    val_split = int(np.floor(val_size * dataset_size))\n",
    "    if shuffle:\n",
    "        np.random.seed(seed)\n",
    "        np.random.shuffle(indices)\n",
    "    train_indices = indices[val_split:]\n",
    "    val_indices = indices[:val_split]\n",
    "\n",
    "    # Creating PT data samplers and loaders:\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = DataLoader(dataset,\n",
    "                              batch_size=batch_train,\n",
    "                              sampler=train_sampler)\n",
    "    val_loader = DataLoader(dataset,\n",
    "                            batch_size=batch_eval,\n",
    "                            sampler=val_sampler)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "class PaddingTransform(object):\n",
    "    def __init__(self, max_length, padding_value=0):\n",
    "        self.max_length = max_length\n",
    "        self.padding_value = padding_value\n",
    "\n",
    "    def __call__(self, s):\n",
    "        if len(s) == self.max_length:\n",
    "            return s\n",
    "\n",
    "        if len(s) > self.max_length:\n",
    "            return s[:self.max_length]\n",
    "\n",
    "        if len(s) < self.max_length:\n",
    "            s1 = copy.deepcopy(s)\n",
    "            pad = np.zeros((self.max_length - s.shape[0], s.shape[1]), dtype=np.float32)\n",
    "            s1 = np.vstack((s1, pad))\n",
    "            return s1\n",
    "        \n",
    "        \n",
    "# Pytorch Dataset Class for creating the dataset\n",
    "class SpectrogramDatasetEmotion(Dataset):\n",
    "    def __init__(self, path, target, train=True, max_length=-1, read_spec_fn=read_fused_spectrogram):\n",
    "        t = 'train' if train else 'test'\n",
    "        p = os.path.join(path, t)\n",
    "        self.index = os.path.join(path, \"{}_labels.txt\".format(t))\n",
    "        self.files, labels = self.get_files_labels(self.index, target)\n",
    "        self.feats = [read_spec_fn(os.path.join(p, f)) for f in self.files]\n",
    "        self.feat_dim = self.feats[0].shape[1]\n",
    "        self.lengths = [len(i) for i in self.feats]\n",
    "        self.max_length = max(self.lengths) if max_length <= 0 else max_length\n",
    "        self.zero_pad_and_stack = PaddingTransform(self.max_length)\n",
    "        if isinstance(labels, (list, tuple)):\n",
    "            self.labels = np.array(np.array(labels).astype('float')).reshape(-1, 3)\n",
    "\n",
    "    def get_files_labels(self, txt, target):\n",
    "        with open(txt, 'r') as fd:\n",
    "            lines = [l.rstrip().split(',') for l in fd.readlines()[1:]]\n",
    "        files, labels = [], []\n",
    "        for l in lines:\n",
    "            if target=='valence':\n",
    "                label = l[1]\n",
    "            elif target=='energy':\n",
    "                label = l[2]\n",
    "            elif target=='danceability':\n",
    "                label = l[3]\n",
    "            else:\n",
    "                label = l[1:]\n",
    "            # Kaggle automatically unzips the npy.gz format so this hack is needed\n",
    "            _id = l[0]\n",
    "            npy_file = '{}.fused.full.npy'.format(_id)\n",
    "            files.append(npy_file)\n",
    "            labels.append(label)\n",
    "        return files, labels\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        l = min(self.lengths[item], self.max_length)\n",
    "        return self.zero_pad_and_stack(self.feats[item]), self.labels[item], l\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-01-18T00:07:00.438494Z",
     "iopub.status.busy": "2021-01-18T00:07:00.437939Z",
     "iopub.status.idle": "2021-01-18T00:07:35.031877Z",
     "shell.execute_reply": "2021-01-18T00:07:35.030492Z"
    },
    "papermill": {
     "duration": 34.605644,
     "end_time": "2021-01-18T00:07:35.031988",
     "exception": false,
     "start_time": "2021-01-18T00:07:00.426344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data with all three labels for multitask\n",
    "specs_multi = SpectrogramDatasetEmotion(\n",
    "         '../input/patreco3-multitask-affective-music/data/multitask_dataset/',\n",
    "         target='multi',\n",
    "         train=True,\n",
    "         max_length=-1,\n",
    "         read_spec_fn=read_fused_spectrogram)\n",
    "    \n",
    "train_loader_multi, val_loader_multi = torch_train_val_split(specs_multi, 32 ,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-01-18T00:07:35.067391Z",
     "iopub.status.busy": "2021-01-18T00:07:35.065784Z",
     "iopub.status.idle": "2021-01-18T00:07:35.068329Z",
     "shell.execute_reply": "2021-01-18T00:07:35.068733Z"
    },
    "papermill": {
     "duration": 0.028416,
     "end_time": "2021-01-18T00:07:35.068836",
     "exception": false,
     "start_time": "2021-01-18T00:07:35.040420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CNN for multitask predictions with shared convolutional layers\n",
    "class ConvBlock(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels):\n",
    "      super(ConvBlock, self).__init__()\n",
    "\n",
    "      self.conv =  nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "      self.batch = nn.BatchNorm2d(out_channels)\n",
    "      self.relu = nn.ReLU()\n",
    "      self.pool = nn.MaxPool2d(kernel_size=3, stride=3)\n",
    "      \n",
    "  def forward(self, x):\n",
    "      return self.pool(self.relu(self.batch(self.conv(x))))\n",
    "      \n",
    "\n",
    "class MultitaskCNN(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super(MultitaskCNN, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            ConvBlock(in_channels=1, out_channels=16),\n",
    "            ConvBlock(in_channels=16, out_channels=32),\n",
    "            ConvBlock(in_channels=32, out_channels=64),\n",
    "            ConvBlock(in_channels=64, out_channels=128),\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1920, 128),\n",
    "            nn.PReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, output_dim),\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1920, 128),\n",
    "            nn.PReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, output_dim),\n",
    "        )\n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1920, 128),\n",
    "            nn.PReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), 1, x.size(1), x.size(2)) # reshape to have 1 channel\n",
    "        x = self.conv(x)\n",
    "        #print(x.size())\n",
    "        return self.fc1(x), self.fc2(x), self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-18T00:07:35.172924Z",
     "iopub.status.busy": "2021-01-18T00:07:35.171063Z",
     "iopub.status.idle": "2021-01-18T00:07:35.173562Z",
     "shell.execute_reply": "2021-01-18T00:07:35.174005Z"
    },
    "papermill": {
     "duration": 0.097059,
     "end_time": "2021-01-18T00:07:35.174139",
     "exception": false,
     "start_time": "2021-01-18T00:07:35.077080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_cnn_multitask(train_dl, val_dl, checkpoint_name):\n",
    "    \n",
    "    # hyper parameters\n",
    "    L2 = 0.0001\n",
    "    EPOCHS = 100  # max epochs\n",
    "    PATIENCE = 5  # for early stopping\n",
    "    \n",
    "\n",
    "    model = MultitaskCNN(output_dim=1)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=L2)\n",
    "    \n",
    "     # set device\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    avg_train_losses = []  # track train loss in each epoch\n",
    "    avg_val_losses = []  # track validation loss in each epoch\n",
    "    min_val_loss = np.Inf\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    # train model\n",
    "    model.train()\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        for i, data in enumerate(train_dl):\n",
    "            X_batch, y_batch, lengths = data\n",
    "            X_batch, y_batch, lengths = X_batch.to(device), y_batch.to(device), lengths.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out1, out2, out3 = model(X_batch.float())\n",
    "            \n",
    "            loss1, loss2, loss3 = criterion(out1, y_batch[:, 0].reshape(-1, 1).float()), criterion(out2, y_batch[:, 1].reshape(-1, 1).float()), criterion(out3, y_batch[:, 2].reshape(-1, 1).float())\n",
    "            loss = 0.4*loss1 + 0.2*loss2 + 0.2*loss3\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # track loss\n",
    "            train_losses.append(loss.detach().item())\n",
    "        avg_train_loss = np.average(train_losses)\n",
    "        avg_train_losses.append(avg_train_loss)\n",
    "\n",
    "        # calculate validation loss and accuracy\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(val_dl):\n",
    "                X_batch, y_batch, lengths = data\n",
    "                X_batch, y_batch, lengths = X_batch.to(device), y_batch.to(device), lengths.to(device)\n",
    "                out1, out2, out3 = model(X_batch.float())\n",
    "                loss1, loss2, loss3 = criterion(out1, y_batch[:, 0].reshape(-1, 1).float()), criterion(out2, y_batch[:, 1].reshape(-1, 1).float()), criterion(out3, y_batch[:, 2].reshape(-1, 1).float())\n",
    "                loss = 0.4*loss1 + 0.2*loss2 + 0.2*loss3\n",
    "                val_losses.append(loss.detach().item())\n",
    "        avg_val_loss = np.average(val_losses)\n",
    "        avg_val_losses.append(avg_val_loss)\n",
    "\n",
    "        # print information\n",
    "        print(\"Epoch: {}  -  loss: {}  -  val_loss: {}\".format(epoch, avg_train_loss, avg_val_loss))\n",
    "\n",
    "        # early stopping\n",
    "        if avg_val_loss < min_val_loss:\n",
    "            torch.save(model, checkpoint_name)  # save checkpoint\n",
    "            epochs_no_improve = 0\n",
    "            min_val_loss = avg_val_loss\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "        if epoch > PATIENCE and epochs_no_improve == PATIENCE:\n",
    "            print('Early stopping')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-18T00:07:35.205575Z",
     "iopub.status.busy": "2021-01-18T00:07:35.204422Z",
     "iopub.status.idle": "2021-01-18T00:07:35.207345Z",
     "shell.execute_reply": "2021-01-18T00:07:35.206924Z"
    },
    "papermill": {
     "duration": 0.024687,
     "end_time": "2021-01-18T00:07:35.207433",
     "exception": false,
     "start_time": "2021-01-18T00:07:35.182746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_cnn_multitask(test_dl, checkpoint_name):\n",
    "    # load best model\n",
    "    model = torch.load(checkpoint_name)\n",
    "    \n",
    "    # set device\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # predict test\n",
    "    model.eval()\n",
    "    test_predictions1 = []\n",
    "    y_test1 = []\n",
    "    test_predictions2 = []\n",
    "    y_test2 = []\n",
    "    test_predictions3 = []\n",
    "    y_test3 = []\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_dl):\n",
    "            X_batch, y_batch, lengths = data\n",
    "            X_batch, y_batch, lengths = X_batch.to(device), y_batch.to(device), lengths.to(device)\n",
    "            out1, out2, out3 = model(X_batch.float())\n",
    "\n",
    "            test_predictions1.extend(out1.detach().cpu().numpy())\n",
    "            y_test1.extend(y_batch[:, 0].tolist())\n",
    "            test_predictions2.extend(out2.detach().cpu().numpy())\n",
    "            y_test2.extend(y_batch[:, 1].tolist())\n",
    "            test_predictions3.extend(out3.detach().cpu().numpy())\n",
    "            y_test3.extend(y_batch[:, 2].tolist())\n",
    "        \n",
    "    corr1 = corr(np.array(y_test1), np.array(test_predictions1)).correlation\n",
    "    corr2 = corr(np.array(y_test2), np.array(test_predictions2)).correlation\n",
    "    corr3 = corr(np.array(y_test3), np.array(test_predictions3)).correlation\n",
    "    \n",
    "    print('Valence:', corr1)\n",
    "    print('Energy:', corr2)\n",
    "    print('Danceability:', corr3)\n",
    "    print('Mean spearman correlation =', (corr1 + corr2 + corr3) / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-18T00:07:35.228979Z",
     "iopub.status.busy": "2021-01-18T00:07:35.228476Z",
     "iopub.status.idle": "2021-01-18T00:09:58.830407Z",
     "shell.execute_reply": "2021-01-18T00:09:58.829743Z"
    },
    "papermill": {
     "duration": 143.614875,
     "end_time": "2021-01-18T00:09:58.830553",
     "exception": false,
     "start_time": "2021-01-18T00:07:35.215678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  -  loss: 0.4936372668578707  -  val_loss: 0.2272947302886418\n",
      "Epoch: 2  -  loss: 0.17821302701686992  -  val_loss: 0.155379661491939\n",
      "Epoch: 3  -  loss: 0.1405390583235642  -  val_loss: 0.10373443790844508\n",
      "Epoch: 4  -  loss: 0.1026848796112784  -  val_loss: 0.09816538648945945\n",
      "Epoch: 5  -  loss: 0.0859972325892284  -  val_loss: 0.08278473679508482\n",
      "Epoch: 6  -  loss: 0.0769959803799103  -  val_loss: 0.07660923153162003\n",
      "Epoch: 7  -  loss: 0.0688127401316988  -  val_loss: 0.06652159935661725\n",
      "Epoch: 8  -  loss: 0.07206780579069565  -  val_loss: 0.06907495962721961\n",
      "Epoch: 9  -  loss: 0.0668307777879567  -  val_loss: 0.070331195635455\n",
      "Epoch: 10  -  loss: 0.05698122238290721  -  val_loss: 0.06156805796282632\n",
      "Epoch: 11  -  loss: 0.057076468293009136  -  val_loss: 0.05214791532073702\n",
      "Epoch: 12  -  loss: 0.05206534433467635  -  val_loss: 0.05508314871362278\n",
      "Epoch: 13  -  loss: 0.05386177694489216  -  val_loss: 0.05465691430228097\n",
      "Epoch: 14  -  loss: 0.05068119056522846  -  val_loss: 0.0475525398339544\n",
      "Epoch: 15  -  loss: 0.046152253603113105  -  val_loss: 0.04943830466696194\n",
      "Epoch: 16  -  loss: 0.04756767161447426  -  val_loss: 0.05362874375922339\n",
      "Epoch: 17  -  loss: 0.040527080089367666  -  val_loss: 0.04647051862307957\n",
      "Epoch: 18  -  loss: 0.0385715857405087  -  val_loss: 0.04311926875795637\n",
      "Epoch: 19  -  loss: 0.04048779099408922  -  val_loss: 0.05163846164941788\n",
      "Epoch: 20  -  loss: 0.0419051919517846  -  val_loss: 0.04247401388628142\n",
      "Epoch: 21  -  loss: 0.03449920898881452  -  val_loss: 0.039288642683199475\n",
      "Epoch: 22  -  loss: 0.036082436234272756  -  val_loss: 0.043615762144327164\n",
      "Epoch: 23  -  loss: 0.03321003457852479  -  val_loss: 0.0432334483734199\n",
      "Epoch: 24  -  loss: 0.032558401918102955  -  val_loss: 0.03785306428159986\n",
      "Epoch: 25  -  loss: 0.035934711645903256  -  val_loss: 0.03672714238720281\n",
      "Epoch: 26  -  loss: 0.032219454903027106  -  val_loss: 0.03722508970115866\n",
      "Epoch: 27  -  loss: 0.0323554967883332  -  val_loss: 0.038579649691070826\n",
      "Epoch: 28  -  loss: 0.030540367267255127  -  val_loss: 0.03308334653931005\n",
      "Epoch: 29  -  loss: 0.029678949636632  -  val_loss: 0.040096969210675786\n",
      "Epoch: 30  -  loss: 0.026876596155865438  -  val_loss: 0.036619678139686584\n",
      "Epoch: 31  -  loss: 0.029292681222331935  -  val_loss: 0.03624965090836797\n",
      "Epoch: 32  -  loss: 0.03216822516044666  -  val_loss: 0.034221497497388294\n",
      "Epoch: 33  -  loss: 0.025528508591754682  -  val_loss: 0.034603803019438474\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "# train cnn for multitask\n",
    "train_cnn_multitask(train_loader_multi, val_loader_multi, 'cnn_multi.th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-18T00:09:58.870860Z",
     "iopub.status.busy": "2021-01-18T00:09:58.870319Z",
     "iopub.status.idle": "2021-01-18T00:09:59.485363Z",
     "shell.execute_reply": "2021-01-18T00:09:59.485994Z"
    },
    "papermill": {
     "duration": 0.636957,
     "end_time": "2021-01-18T00:09:59.486140",
     "exception": false,
     "start_time": "2021-01-18T00:09:58.849183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence: 0.5874439689660799\n",
      "Energy: 0.7652111243929229\n",
      "Danceability: 0.7091738898704709\n",
      "Mean spearman correlation = 0.6872763277431578\n"
     ]
    }
   ],
   "source": [
    "# evaluate cnn for valence\n",
    "valence_corr = evaluate_cnn_multitask(val_loader_multi, 'cnn_multi.th')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017875,
     "end_time": "2021-01-18T00:09:59.522331",
     "exception": false,
     "start_time": "2021-01-18T00:09:59.504456",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Step 10: Kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-18T00:09:59.569434Z",
     "iopub.status.busy": "2021-01-18T00:09:59.568217Z",
     "iopub.status.idle": "2021-01-18T00:09:59.570670Z",
     "shell.execute_reply": "2021-01-18T00:09:59.571089Z"
    },
    "papermill": {
     "duration": 0.030588,
     "end_time": "2021-01-18T00:09:59.571192",
     "exception": false,
     "start_time": "2021-01-18T00:09:59.540604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDatasetEmotion(Dataset):\n",
    "    def __init__(self, path, max_length=-1, read_spec_fn=read_fused_spectrogram):\n",
    "        p = os.path.join(path, 'test')\n",
    "        self.files = os.listdir(p)\n",
    "        self.feats = [read_spec_fn(os.path.join(p, f)) for f in self.files]\n",
    "        self.files = [file+'.gz' for file in os.listdir(p)]              \n",
    "        self.feat_dim = self.feats[0].shape[1]\n",
    "        self.lengths = [len(i) for i in self.feats]\n",
    "        self.max_length = max(self.lengths) if max_length <= 0 else max_length\n",
    "        self.zero_pad_and_stack = PaddingTransform(self.max_length)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        l = min(self.lengths[item], self.max_length)\n",
    "        return self.zero_pad_and_stack(self.feats[item]), self.files[item], l\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-18T00:09:59.611509Z",
     "iopub.status.busy": "2021-01-18T00:09:59.610973Z",
     "iopub.status.idle": "2021-01-18T00:10:13.124278Z",
     "shell.execute_reply": "2021-01-18T00:10:13.123169Z"
    },
    "papermill": {
     "duration": 13.535245,
     "end_time": "2021-01-18T00:10:13.124398",
     "exception": false,
     "start_time": "2021-01-18T00:09:59.589153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data with all three labels for multitask\n",
    "specs_multi_test = TestDatasetEmotion(\n",
    "         '../input/patreco3-multitask-affective-music/data/multitask_dataset/',\n",
    "         read_spec_fn=read_fused_spectrogram)\n",
    "\n",
    "test_loader_multi = DataLoader(specs_multi_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-18T00:10:13.173709Z",
     "iopub.status.busy": "2021-01-18T00:10:13.172849Z",
     "iopub.status.idle": "2021-01-18T00:10:14.379975Z",
     "shell.execute_reply": "2021-01-18T00:10:14.379467Z"
    },
    "papermill": {
     "duration": 1.236985,
     "end_time": "2021-01-18T00:10:14.380108",
     "exception": false,
     "start_time": "2021-01-18T00:10:13.143123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create submission file\n",
    "# load best model\n",
    "model = torch.load('cnn_multi.th')\n",
    "    \n",
    "# set device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "    \n",
    "# predict test\n",
    "model.eval()\n",
    "test_predictions1 = []\n",
    "test_predictions2 = []\n",
    "test_predictions3 = []\n",
    "filenames = []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader_multi):\n",
    "        X_batch, files, lengths = data\n",
    "        X_batch, lengths = X_batch.to(device), lengths.to(device)\n",
    "        out1, out2, out3 = model(X_batch.float())\n",
    "        \n",
    "        test_predictions1.extend(out1.detach().cpu().numpy())\n",
    "        test_predictions2.extend(out2.detach().cpu().numpy())\n",
    "        test_predictions3.extend(out3.detach().cpu().numpy())\n",
    "        filenames.extend(files)\n",
    "            \n",
    "submission = pd.DataFrame()\n",
    "submission[\"Id.fused.full.npy.gz\"] = filenames\n",
    "submission[\"valence\"] = np.array(test_predictions1).flatten()\n",
    "submission[\"energy\"] = np.array(test_predictions2).flatten()\n",
    "submission[\"danceability\"] = np.array(test_predictions3).flatten()\n",
    "submission.to_csv('solution2.txt', index=False)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 200.435734,
   "end_time": "2021-01-18T00:10:15.006280",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-18T00:06:54.570546",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
